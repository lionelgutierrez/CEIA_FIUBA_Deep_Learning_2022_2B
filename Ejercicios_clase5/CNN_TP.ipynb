{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N9_1a5iymIvC"
   },
   "source": [
    "## EJERCICIO\n",
    "\n",
    "Vamos a armar una pequeña competición en el curso.\n",
    "El objetivo es armar una arquitectura de CNN que identifique el dataset MNIST.\n",
    "Se van a usar capas de convolución, de activación y de pooling a elección. Cada alumno eligirá su modelo y los respectivos hiperparámetros, lo entrenará y presentará los siguientes resultados:\n",
    "\n",
    "*   `test_acc` (del test final)\n",
    "*   `n_parameter`\n",
    "*   `n_layers` (conv + activacion + pooling = 1 capa)\n",
    "*   `n_epochs` de entrenamiento usadas.\n",
    "\n",
    "\n",
    "El modelo se deberá ajustar a los siguientes parámetros:\n",
    "\n",
    "*   train: 80%, validation: 10%, test: 10% (los datos serán dados así todos usan el mismo set para cada grupo. Están en el github el curso).\n",
    "*   capa final de salida será una softmax de 10 elementos.\n",
    "*   coss_function será `CrossEntropyLoss`.\n",
    "\n",
    "El ganador de la competencia será aquel que consiga el mayor `score` empleando la siguietne fórmula:\n",
    "\n",
    "$$ score = \\frac{1}{log_{10}(n\\_parameter)} * \\frac{10}{n\\_epochs}*test\\_acc*n\\_layers$$\n",
    "\n",
    "Deberan presentar su código colab funcionando y el score alcanzado (con los valores de cada variable que compone el score).\n",
    "\n",
    "Es una competencia fairplay y con fines didácticos, esta formula del ```score``` fué inventada.... no usar como referencia para definir qué modelo utilizar.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_wIQ8hjDpdVi"
   },
   "source": [
    "### Importar lo necesario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "uHQUjDs12DLW"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from google.colab import drive \n",
    "import os\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QeJy8fjPn4wi"
   },
   "source": [
    "### configuramos el `device` acorde al device disponible\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lOV9xybtn4I3"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "2cOcGesN7dS1",
    "outputId": "11ba7ff4-a079-447e-b6f9-10f9b987d653"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1nQ-MLk6Do8e"
   },
   "source": [
    "### 1. Cargar base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YVtYG9re7qKw",
    "outputId": "52f135da-5986-4e32-9846-cb0ddf649a04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['CNN_TP.ipynb',\n",
       " 'test_label.pkl',\n",
       " 'test.pkl',\n",
       " 'val_label.pkl',\n",
       " 'val.pkl',\n",
       " 'train.pkl',\n",
       " 'train_label.pkl',\n",
       " 'CNN_implementacion.ipynb']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drive.mount('/content/drive')\n",
    "path = '../content/drive/MyDrive/CEIA/TPS/DeepLearning'\n",
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "DBh6A0jiCX18"
   },
   "outputs": [],
   "source": [
    "def cargarArchivo(ruta):\n",
    "  file = open(ruta,\"rb\")\n",
    "  datos = pickle.load(file)\n",
    "  file.close()\n",
    "  return datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "W8bftsEo6l9j"
   },
   "outputs": [],
   "source": [
    "test_label = torch.from_numpy(cargarArchivo(path+\"/test_label.pkl\"))\n",
    "test = torch.from_numpy(cargarArchivo(path+\"/test.pkl\")).type(torch.FloatTensor)\n",
    "train_label = torch.from_numpy(cargarArchivo(path+\"/train_label.pkl\"))\n",
    "train = torch.from_numpy(cargarArchivo(path+\"/train.pkl\")).type(torch.FloatTensor)\n",
    "val_label = torch.from_numpy(cargarArchivo(path+\"/val_label.pkl\"))\n",
    "val = torch.from_numpy(cargarArchivo(path+\"/val.pkl\")).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "rrzS_7MULIJQ"
   },
   "outputs": [],
   "source": [
    "def normaliza(ds):\n",
    "  # I can get what I want from below for-loop solution\n",
    "  batches = ds.shape[0]\n",
    "  for i in range(batches):\n",
    "      ds[i] -= torch.min(ds[i])\n",
    "      ds[i] /= torch.max(ds[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "tp52hTe_LbA5"
   },
   "outputs": [],
   "source": [
    "normaliza(train)\n",
    "normaliza(test)\n",
    "normaliza(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x_heQCz685hN",
    "outputId": "e98d9205-7611-4479-927c-ff4621e3d429"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de train_label: torch.Size([56000])\n",
      "Shape de train: torch.Size([56000, 28, 28])\n",
      "Shape de test_label: torch.Size([7000])\n",
      "Shape de test: torch.Size([7000, 28, 28])\n",
      "Shape de val_label: torch.Size([7000])\n",
      "Shape de val: torch.Size([7000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape de train_label:\",train_label.shape)\n",
    "print(\"Shape de train:\",train.shape)\n",
    "print(\"Shape de test_label:\",test_label.shape)\n",
    "print(\"Shape de test:\",test.shape)\n",
    "print(\"Shape de val_label:\",val_label.shape)\n",
    "print(\"Shape de val:\",val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "LpOnK_10B01n"
   },
   "outputs": [],
   "source": [
    "class CNNDataset(Dataset):\n",
    "\n",
    "    def __init__(self, X_Train, Y_Train, transform=None):\n",
    "        self.X_Train = X_Train\n",
    "        self.Y_Train = Y_Train\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_Train)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.X_Train[idx]\n",
    "        y = self.Y_Train[idx]\n",
    "\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "cox9Ey3lKc9h"
   },
   "outputs": [],
   "source": [
    "#paso a shape num_muestras, chanel, H, W\n",
    "train = torch.unsqueeze(train,1)\n",
    "test = torch.unsqueeze(test,1)\n",
    "val = torch.unsqueeze(val,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Sx3_R9kWDz0K"
   },
   "outputs": [],
   "source": [
    "#train_dataset = CNNDataset(torch.unsqueeze(train,1), train_label)\n",
    "#test_dataset =  CNNDataset(torch.unsqueeze(test,1), test_label)\n",
    "#validation_dataset = CNNDataset(torch.unsqueeze(val,1), val_label)\n",
    "train_dataset = CNNDataset(train, train_label)\n",
    "test_dataset =  CNNDataset(test, test_label)\n",
    "validation_dataset = CNNDataset(val, val_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "mXmEGv7dDeRw"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "dataloader = {\n",
    "    'train': torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True),\n",
    "    'test': torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True),\n",
    "    'validation': torch.utils.data.DataLoader(validation_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oikthAE4Dteb"
   },
   "source": [
    "2. Ver que la base de datos esté OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cyq2UFIl-Qjy",
    "outputId": "2cc9522f-2a1e-482a-c1dc-deee22f9eb27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n"
     ]
    }
   ],
   "source": [
    "print(type(dataloader))\n",
    "print(type(dataloader['train']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z-JASLqsEdxK"
   },
   "source": [
    "### 3. Pruebo ver una imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 352
    },
    "id": "p2fs6Qdivs1H",
    "outputId": "29d84366-c6af-4ee6-8fe6-fa546f426a94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
      "Labels batch shape: torch.Size([64])\n",
      "tamaño de 1 imagen:  torch.Size([1, 28, 28])\n",
      "tamaño 1 imagen DESPUES de squeeze:  torch.Size([28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 3\n"
     ]
    }
   ],
   "source": [
    "# Display image and label from dataloader (dataloader -> una herramienta para hacer batches de datasets)\n",
    "train_features, train_labels = next(iter(dataloader['train']))\n",
    "\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "\n",
    "indice = 4\n",
    "img = train_features[indice]\n",
    "print('tamaño de 1 imagen: ', img.shape)\n",
    "# le QUITO 1 dimension (la del tamaño del batch) para poder graficar\n",
    "img = train_features[indice].squeeze()\n",
    "print('tamaño 1 imagen DESPUES de squeeze: ', img.shape)\n",
    "label = train_labels[indice]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EY0TN4erDxRd"
   },
   "source": [
    "### 4.1 Construyo mi CNN base\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "HDeYdSRDTs6C"
   },
   "outputs": [],
   "source": [
    "# defino primero un \"bloque\" de una capa CNN\n",
    "# construido con los bloques funcionales vistos en clase\n",
    "#\n",
    "# (hiper)parámetros a pasar a la función:\n",
    "#   c_in:   canales (kernels) de entrada\n",
    "#   c_out:  canales (kernels) de salida\n",
    "#   k:      tamaño del kernel kxk\n",
    "#   p:      tamaño del padding de la convolución\n",
    "#   s:      stride de la convolución\n",
    "#   pk:     tamaño del kernel del pooling\n",
    "#   ps:     stride de la pooling\n",
    "#   pp:     padding en la pooling\n",
    "#\n",
    "#   la función pooling se elige directamente dentro del bloque!\n",
    "\n",
    "def block(c_in, c_out, k=3, p=1, s=1, pk=3, ps=2, pp=1):\n",
    "    return torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(c_in, c_out, k, padding=p, stride=s), # conv\n",
    "        torch.nn.ReLU(),                                      # activation\n",
    "        torch.nn.MaxPool2d(pk, stride=ps, padding=pp)         # pooling\n",
    "    )\n",
    "\n",
    "\n",
    "# ahora SI construyo mi red... usando la clase CNN de pytorch\n",
    "# revisar muy bien las dimensiones a emplear en cada capa y\n",
    "# tener presente la reducción de las dimensiones.\n",
    "#\n",
    "# en la útlima capa fully conected 'fc', hacer bien el cálculo final del\n",
    "# tamaño del array que se obtiene siguiendo la formula vista en la teoria\n",
    "# tanto para la capa conv como para la capa pooling.\n",
    "#\n",
    "class CNN(torch.nn.Module):\n",
    "  def __init__(self, n_channels=1, n_outputs=10):\n",
    "    super().__init__()\n",
    "    self.conv1 = block(n_channels, 64)\n",
    "    self.conv1_out = None\n",
    "    self.conv2 = block(64, 128)\n",
    "    self.conv2_out = None\n",
    "    #self.conv3 = block(128, 128)\n",
    "    #self.conv3_out = None\n",
    "    #self.conv4 = block(128, 128)\n",
    "    #self.conv4_out = None\n",
    "    self.fc = torch.nn.Linear(128*7*7, n_outputs) # verificar la dim de la salida para calcular el tamaño de la fully conected!!\n",
    "    #self.sm = torch.nn.Softmax(dim=1)\n",
    "    print('Red creada')\n",
    "    print('arquitectura:')\n",
    "    print(self)\n",
    "    # Me fijo en el número de capas\n",
    "    i=0\n",
    "    for layer in self.children():\n",
    "        i=i+1\n",
    "    print('Número total de capas de CNN (conv+act+polling) + finales : ', i)\n",
    "    \n",
    "    # Me fijo en el número de parámetros entrenables\n",
    "    pytorch_total_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "    print('Número total de parámetros a entrenar: ', pytorch_total_params)\n",
    "    self.tot_capas=i\n",
    "    self.tot_param=pytorch_total_params    \n",
    "\n",
    "  def validar_dim(self,tam):\n",
    "    # es una funcion forward que imprime la dimension de cada paso\n",
    "    # la defino distinto de la forward standard para que cuando entrenemos\n",
    "    # no nos llene la pantalla de información inecesaria.\n",
    "\n",
    "    print(\"Validacion de dimensiones\")\n",
    "    #tam = input(\"Ingrese tamaño de entrada: \")\n",
    "    x = torch.randn(1, 1, int(tam), int(tam))\n",
    "    print(\"Tamaño entrada: \", x.shape)\n",
    "    x = self.conv1(x)\n",
    "    print(\"Tamaño salida conv1: \", x.shape)\n",
    "    x = self.conv2(x)\n",
    "    print(\"Tamaño salida conv2: \", x.shape)\n",
    "\n",
    "    #x = self.conv3(x)\n",
    "    #print(\"Tamaño salida conv3: \", x.shape)\n",
    "\n",
    "    #x = self.conv4(x)\n",
    "    #print(\"Tamaño salida conv4: \", x.shape)\n",
    "\n",
    "    x = x.view(x.shape[0], -1)\n",
    "    print(\"Tamaño imagen vectorizada: \", x.shape)\n",
    "    x = self.fc(x)\n",
    "    print(\"Tamaño salida fc (nro clases): \", x.shape)\n",
    "\n",
    "  def forward(self, x):\n",
    "    self.conv1_out = self.conv1(x)\n",
    "    self.conv2_out = self.conv2(self.conv1_out)\n",
    "    #self.conv3_out = self.conv3(self.conv2_out)\n",
    "    #self.conv4_out = self.conv4(self.conv3_out)\n",
    "    y = self.conv2_out.view(self.conv2_out.shape[0], -1)\n",
    "    y = self.fc(y)\n",
    "    y = torch.nn.functional.softmax(y, dim=1)\n",
    "    # x = self.sm(x)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "54uJtmF8TZk1"
   },
   "source": [
    "### 4.2 Construyo mi CNN version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "680NX-28OeVz"
   },
   "outputs": [],
   "source": [
    "def block(c_in, c_out, k=3, p=1, s=1, pk=3, ps=2, pp=1):\n",
    "    return torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(c_in, c_out, k, padding=p, stride=s), # conv\n",
    "        torch.nn.ReLU(),                                      # activation\n",
    "        torch.nn.MaxPool2d(pk, stride=ps, padding=pp)         # pooling\n",
    "    )\n",
    "\n",
    "class CNN2(torch.nn.Module):\n",
    "  def __init__(self, n_channels=1, n_outputs=10):\n",
    "    super().__init__()\n",
    "    self.conv1 = block(n_channels, 4,k=5,pk=2,ps=2)\n",
    "    self.conv1_out = None\n",
    "    self.conv2 = block(4, 4,k=3,pk=2,ps=2)\n",
    "    self.conv2_out = None\n",
    "    self.conv3 = block(4, 4,k=3,pk=2,ps=2)\n",
    "    self.conv3_out = None\n",
    "    self.conv4 = block(4, 4,k=3,pk=2,ps=2)\n",
    "    self.conv4_out = None\n",
    "    self.conv5 = block(4, 4,k=3,pk=2,ps=2)\n",
    "    self.conv5_out = None\n",
    "    self.conv6 = block(4, 4,k=3,pk=2,ps=2)\n",
    "    self.conv6_out = None\n",
    "    self.fc = torch.nn.Linear(4*2*2, n_outputs) # verificar la dim de la salida para calcular el tamaño de la fully conected!!\n",
    "    #self.sm = torch.nn.Softmax(dim=1)\n",
    "    print('Red creada')\n",
    "    print('arquitectura:')\n",
    "    print(self)\n",
    "    # Me fijo en el número de capas\n",
    "    i=0\n",
    "    for layer in self.children():\n",
    "        i=i+1\n",
    "    print('Número total de capas de CNN (conv+act+polling) + finales : ', i)\n",
    "    \n",
    "    # Me fijo en el número de parámetros entrenables\n",
    "    pytorch_total_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "    print('Número total de parámetros a entrenar: ', pytorch_total_params)\n",
    "    self.tot_capas=i\n",
    "    self.tot_param=pytorch_total_params    \n",
    "\n",
    "  def validar_dim(self,tam):\n",
    "    # es una funcion forward que imprime la dimension de cada paso\n",
    "    # la defino distinto de la forward standard para que cuando entrenemos\n",
    "    # no nos llene la pantalla de información inecesaria.\n",
    "\n",
    "    print(\"Validacion de dimensiones\")\n",
    "    x = torch.randn(1, 1, int(tam), int(tam))\n",
    "    print(\"Tamaño entrada: \", x.shape)\n",
    "    x = self.conv1(x)\n",
    "    print(\"Tamaño salida conv1: \", x.shape)\n",
    "    x = self.conv2(x)\n",
    "    print(\"Tamaño salida conv2: \", x.shape)\n",
    "    x = self.conv3(x)\n",
    "    print(\"Tamaño salida conv3: \", x.shape)\n",
    "    x = self.conv4(x)\n",
    "    print(\"Tamaño salida conv4: \", x.shape)\n",
    "    x = self.conv5(x)\n",
    "    print(\"Tamaño salida conv5: \", x.shape)    \n",
    "    x = self.conv6(x)\n",
    "    print(\"Tamaño salida conv6: \", x.shape)\n",
    "\n",
    "    x = x.view(x.shape[0], -1)\n",
    "    print(\"Tamaño imagen vectorizada: \", x.shape)\n",
    "    x = self.fc(x)\n",
    "    print(\"Tamaño salida fc (nro clases): \", x.shape)\n",
    "\n",
    "  def forward(self, x):\n",
    "    self.conv1_out = self.conv1(x)\n",
    "    self.conv2_out = self.conv2(self.conv1_out)\n",
    "    self.conv3_out = self.conv3(self.conv2_out)\n",
    "    self.conv4_out = self.conv4(self.conv3_out)\n",
    "    self.conv5_out = self.conv5(self.conv4_out)\n",
    "    self.conv6_out = self.conv6(self.conv5_out)\n",
    "    y = self.conv6_out.view(self.conv6_out.shape[0], -1)\n",
    "    y = self.fc(y)\n",
    "    y = torch.nn.functional.softmax(y, dim=1)\n",
    "    # x = self.sm(x)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQ04WnePII_6"
   },
   "source": [
    "### 4.3 Construyo mi CNN version 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "OPwJBRwvII_7"
   },
   "outputs": [],
   "source": [
    "def block(c_in, c_out, k=3, p=1, s=1, pk=3, ps=2, pp=1):\n",
    "    return torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(c_in, c_out, k, padding=p, stride=s), # conv\n",
    "        torch.nn.ReLU(),                                      # activation\n",
    "        torch.nn.MaxPool2d(pk, stride=ps, padding=pp)         # pooling\n",
    "    )\n",
    "\n",
    "class CNN3(torch.nn.Module):\n",
    "  def __init__(self, n_channels=1, n_outputs=10):\n",
    "    super().__init__()\n",
    "    self.conv1 = block(n_channels, 4,k=3,pk=2,ps=2)\n",
    "    self.conv1_out = None\n",
    "    self.conv2 = block(4, 4,k=3,pk=2,ps=2)\n",
    "    self.conv2_out = None\n",
    "    self.conv3 = block(4, 4,k=3,pk=2,ps=2)\n",
    "    self.conv3_out = None\n",
    "    self.conv4 = block(4, 4,k=3,pk=2,ps=2)\n",
    "    self.conv4_out = None\n",
    "    self.conv5 = block(4, 4,k=3,pk=2,ps=2)\n",
    "    self.conv5_out = None\n",
    "    self.conv6 = block(4, 4,k=3,pk=2,ps=2)\n",
    "    self.conv6_out = None\n",
    "    self.conv7 = block(4, 4,k=3,pk=2,ps=2)\n",
    "    self.conv7_out = None\n",
    "    self.fc = torch.nn.Linear(4*2*2, n_outputs) # verificar la dim de la salida para calcular el tamaño de la fully conected!!\n",
    "    #self.sm = torch.nn.Softmax(dim=1)\n",
    "    print('Red creada')\n",
    "    print('arquitectura:')\n",
    "    print(self)\n",
    "    # Me fijo en el número de capas\n",
    "    i=0\n",
    "    for layer in self.children():\n",
    "        i=i+1\n",
    "    print('Número total de capas de CNN (conv+act+polling) + finales : ', i)\n",
    "    \n",
    "    # Me fijo en el número de parámetros entrenables\n",
    "    pytorch_total_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "    print('Número total de parámetros a entrenar: ', pytorch_total_params)\n",
    "    self.tot_capas=i\n",
    "    self.tot_param=pytorch_total_params    \n",
    "\n",
    "  def validar_dim(self,tam):\n",
    "    # es una funcion forward que imprime la dimension de cada paso\n",
    "    # la defino distinto de la forward standard para que cuando entrenemos\n",
    "    # no nos llene la pantalla de información inecesaria.\n",
    "\n",
    "    print(\"Validacion de dimensiones\")\n",
    "    #tam = input(\"Ingrese tamaño de entrada: \")\n",
    "    x = torch.randn(1, 1, int(tam), int(tam))\n",
    "    print(\"Tamaño entrada: \", x.shape)\n",
    "    x = self.conv1(x)\n",
    "    print(\"Tamaño salida conv1: \", x.shape)\n",
    "    x = self.conv2(x)\n",
    "    print(\"Tamaño salida conv2: \", x.shape)\n",
    "    x = self.conv3(x)\n",
    "    print(\"Tamaño salida conv3: \", x.shape)\n",
    "    x = self.conv4(x)\n",
    "    print(\"Tamaño salida conv4: \", x.shape)\n",
    "    x = self.conv5(x)\n",
    "    print(\"Tamaño salida conv5: \", x.shape)    \n",
    "    x = self.conv6(x)\n",
    "    print(\"Tamaño salida conv6: \", x.shape)\n",
    "\n",
    "    x = x.view(x.shape[0], -1)\n",
    "    print(\"Tamaño imagen vectorizada: \", x.shape)\n",
    "    x = self.fc(x)\n",
    "    print(\"Tamaño salida fc (nro clases): \", x.shape)\n",
    "\n",
    "  def forward(self, x):\n",
    "    self.conv1_out = self.conv1(x)\n",
    "    self.conv2_out = self.conv2(self.conv1_out)\n",
    "    self.conv3_out = self.conv3(self.conv2_out)\n",
    "    self.conv4_out = self.conv4(self.conv3_out)\n",
    "    self.conv5_out = self.conv5(self.conv4_out)\n",
    "    self.conv6_out = self.conv6(self.conv5_out)\n",
    "    y = self.conv6_out.view(self.conv6_out.shape[0], -1)\n",
    "    y = self.fc(y)\n",
    "    y = torch.nn.functional.softmax(y, dim=1)\n",
    "    # x = self.sm(x)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "idisipLmZJLR"
   },
   "source": [
    "### 4.4 Construyo mi CNN version 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "ifiyQ8S3ZJLX"
   },
   "outputs": [],
   "source": [
    "def block(c_in, c_out, k=3, p=1, s=1, pk=3, ps=2, pp=1):\n",
    "    return torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(c_in, c_out, k, padding=p, stride=s), # conv\n",
    "        torch.nn.ReLU(),                                      # activation\n",
    "        torch.nn.MaxPool2d(pk, stride=ps, padding=pp)         # pooling\n",
    "    )\n",
    "\n",
    "class CNN4(torch.nn.Module):\n",
    "  def __init__(self, n_channels=1, n_outputs=10):\n",
    "    super().__init__()\n",
    "    self.conv1 = block(n_channels, 4,k=2,pk=2,ps=2)\n",
    "    self.conv1_out = None\n",
    "    self.conv2 = block(4, 4,k=2,pk=2,ps=2)\n",
    "    self.conv2_out = None\n",
    "    self.conv3 = block(4, 4,k=2,pk=2,ps=2)\n",
    "    self.conv3_out = None\n",
    "    self.conv4 = block(4, 4,k=2,pk=2,ps=2)\n",
    "    self.conv4_out = None\n",
    "    self.conv5 = block(4, 4,k=2,pk=2,ps=2)\n",
    "    self.conv5_out = None\n",
    "    self.conv6 = block(4, 4,k=2,pk=2,ps=2)\n",
    "    self.conv6_out = None\n",
    "    self.conv7 = block(4, 4,k=2,pk=2,ps=2)\n",
    "    self.conv7_out = None\n",
    "    self.conv8 = block(4, 4,k=2,pk=2,ps=2)\n",
    "    self.conv8_out = None\n",
    "    self.conv9 = block(4, 4,k=2,pk=2,ps=2)\n",
    "    self.conv9_out = None        \n",
    "    self.conv10 = block(4, 4,k=2,pk=2,ps=2)\n",
    "    self.conv10_out = None\n",
    "    self.conv11 = block(4, 4,k=2,pk=2,ps=2)\n",
    "    self.conv11_out = None        \n",
    "    self.fc = torch.nn.Linear(4*3*3, n_outputs) # verificar la dim de la salida para calcular el tamaño de la fully conected!!\n",
    "    #self.sm = torch.nn.Softmax(dim=1)\n",
    "    print('Red creada')\n",
    "    print('arquitectura:')\n",
    "    print(self)\n",
    "    # Me fijo en el número de capas\n",
    "    i=0\n",
    "    for layer in self.children():\n",
    "        i=i+1\n",
    "    print('Número total de capas de CNN (conv+act+polling) + finales : ', i)\n",
    "    self.tot_capas=i\n",
    "    # Me fijo en el número de parámetros entrenables\n",
    "    pytorch_total_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "    print('Número total de parámetros a entrenar: ', pytorch_total_params)\n",
    "    self.tot_param=pytorch_total_params\n",
    "\n",
    "  def validar_dim(self,tam):\n",
    "    # es una funcion forward que imprime la dimension de cada paso\n",
    "    # la defino distinto de la forward standard para que cuando entrenemos\n",
    "    # no nos llene la pantalla de información inecesaria.\n",
    "\n",
    "    print(\"Validacion de dimensiones\")\n",
    "    #tam = input(\"Ingrese tamaño de entrada: \")\n",
    "    x = torch.randn(1, 1, int(tam), int(tam))\n",
    "    print(\"Tamaño entrada: \", x.shape)\n",
    "    x = self.conv1(x)\n",
    "    print(\"Tamaño salida conv1: \", x.shape)\n",
    "    x = self.conv2(x)\n",
    "    print(\"Tamaño salida conv2: \", x.shape)\n",
    "    x = self.conv3(x)\n",
    "    print(\"Tamaño salida conv3: \", x.shape)\n",
    "    x = self.conv4(x)\n",
    "    print(\"Tamaño salida conv4: \", x.shape)\n",
    "    x = self.conv5(x)\n",
    "    print(\"Tamaño salida conv5: \", x.shape)    \n",
    "    x = self.conv6(x)\n",
    "    print(\"Tamaño salida conv6: \", x.shape)\n",
    "    x = self.conv7(x)\n",
    "    print(\"Tamaño salida conv7: \", x.shape)\n",
    "    x = self.conv8(x)\n",
    "    print(\"Tamaño salida conv8: \", x.shape)\n",
    "    x = self.conv9(x)\n",
    "    print(\"Tamaño salida conv9: \", x.shape)\n",
    "    x = self.conv10(x)\n",
    "    print(\"Tamaño salida conv10: \", x.shape)\n",
    "    x = self.conv11(x)\n",
    "    print(\"Tamaño salida conv11: \", x.shape)                \n",
    "    x = x.view(x.shape[0], -1)\n",
    "    print(\"Tamaño imagen vectorizada: \", x.shape)\n",
    "    x = self.fc(x)\n",
    "    print(\"Tamaño salida fc (nro clases): \", x.shape)\n",
    "\n",
    "  def forward(self, x):\n",
    "    self.conv1_out = self.conv1(x)\n",
    "    self.conv2_out = self.conv2(self.conv1_out)\n",
    "    self.conv3_out = self.conv3(self.conv2_out)\n",
    "    self.conv4_out = self.conv4(self.conv3_out)\n",
    "    self.conv5_out = self.conv5(self.conv4_out)\n",
    "    self.conv6_out = self.conv6(self.conv5_out)\n",
    "    self.conv7_out = self.conv7(self.conv6_out)\n",
    "    self.conv8_out = self.conv8(self.conv7_out)\n",
    "    self.conv9_out = self.conv9(self.conv8_out)\n",
    "    self.conv10_out = self.conv10(self.conv9_out)\n",
    "    self.conv11_out = self.conv11(self.conv10_out)\n",
    "    y = self.conv11_out.view(self.conv11_out.shape[0], -1)\n",
    "    y = self.fc(y)\n",
    "    y = torch.nn.functional.softmax(y, dim=1)\n",
    "    # x = self.sm(x)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V1NQ34fQiFf9"
   },
   "source": [
    "### 4.4 Construyo mi CNN version 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "LVKxSTWgiFgE"
   },
   "outputs": [],
   "source": [
    "def block(c_in, c_out, k=3, p=1, s=1, pk=3, ps=2, pp=1):\n",
    "    return torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(c_in, c_out, k, padding=p, stride=s), # conv\n",
    "        torch.nn.ReLU(),                                      # activation\n",
    "        torch.nn.MaxPool2d(pk, stride=ps, padding=pp)         # pooling\n",
    "    )\n",
    "\n",
    "class CNN5(torch.nn.Module):\n",
    "  def __init__(self, n_channels=1, n_outputs=10):\n",
    "    super().__init__()\n",
    "    self.conv1 = block(n_channels, 8,k=3,pk=2,ps=1)\n",
    "    self.conv1_out = None\n",
    "    self.conv2 = block(8, 8,k=5,pk=2,ps=1)\n",
    "    self.conv2_out = None\n",
    "    self.conv3 = block(8, 8,k=3,pk=2,ps=2)\n",
    "    self.conv3_out = None\n",
    "    self.conv4 = block(8, 8,k=2,pk=2,ps=1)\n",
    "    self.conv4_out = None\n",
    "    self.conv5 = block(8, 8,k=3,pk=2,ps=2)\n",
    "    self.conv5_out = None\n",
    "    self.conv6 = block(8, 8,k=2,pk=2,ps=1)\n",
    "    self.conv6_out = None\n",
    "    self.conv7 = block(8, 8,k=2,pk=2,ps=2)\n",
    "    self.conv7_out = None\n",
    "    self.conv8 = block(8, 8,k=3,pk=2,ps=1)\n",
    "    self.conv8_out = None\n",
    "    self.conv9 = block(8, 8,k=2,pk=2,ps=2)\n",
    "    self.conv9_out = None        \n",
    "    self.conv10 = block(8,8,k=2,pk=2,ps=2)\n",
    "    self.conv10_out = None\n",
    "    self.conv11 = block(8, 8,k=2,pk=2,ps=2)\n",
    "    self.conv11_out = None        \n",
    "    self.fc = torch.nn.Linear(8*3*3, n_outputs) # verificar la dim de la salida para calcular el tamaño de la fully conected!!\n",
    "    #self.sm = torch.nn.Softmax(dim=1)\n",
    "    print('Red creada')\n",
    "    print('arquitectura:')\n",
    "    print(self)\n",
    "    # Me fijo en el número de capas\n",
    "    i=0\n",
    "    for layer in self.children():\n",
    "        i=i+1\n",
    "    print('Número total de capas de CNN (conv+act+polling) + finales : ', i)\n",
    "    self.tot_capas=i\n",
    "    # Me fijo en el número de parámetros entrenables\n",
    "    pytorch_total_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "    print('Número total de parámetros a entrenar: ', pytorch_total_params)\n",
    "    self.tot_param=pytorch_total_params\n",
    "\n",
    "  def validar_dim(self,tam):\n",
    "    # es una funcion forward que imprime la dimension de cada paso\n",
    "    # la defino distinto de la forward standard para que cuando entrenemos\n",
    "    # no nos llene la pantalla de información inecesaria.\n",
    "\n",
    "    print(\"Validacion de dimensiones\")\n",
    "    #tam = input(\"Ingrese tamaño de entrada: \")\n",
    "    x = torch.randn(1, 1, int(tam), int(tam))\n",
    "    print(\"Tamaño entrada: \", x.shape)\n",
    "    x = self.conv1(x)\n",
    "    print(\"Tamaño salida conv1: \", x.shape)\n",
    "    x = self.conv2(x)\n",
    "    print(\"Tamaño salida conv2: \", x.shape)\n",
    "    x = self.conv3(x)\n",
    "    print(\"Tamaño salida conv3: \", x.shape)\n",
    "    x = self.conv4(x)\n",
    "    print(\"Tamaño salida conv4: \", x.shape)\n",
    "    x = self.conv5(x)\n",
    "    print(\"Tamaño salida conv5: \", x.shape)    \n",
    "    x = self.conv6(x)\n",
    "    print(\"Tamaño salida conv6: \", x.shape)\n",
    "    x = self.conv7(x)\n",
    "    print(\"Tamaño salida conv7: \", x.shape)\n",
    "    x = self.conv8(x)\n",
    "    print(\"Tamaño salida conv8: \", x.shape)\n",
    "    x = self.conv9(x)\n",
    "    print(\"Tamaño salida conv9: \", x.shape)\n",
    "    x = self.conv10(x)\n",
    "    print(\"Tamaño salida conv10: \", x.shape)\n",
    "    x = self.conv11(x)\n",
    "    print(\"Tamaño salida conv11: \", x.shape)                \n",
    "    x = x.view(x.shape[0], -1)\n",
    "    print(\"Tamaño imagen vectorizada: \", x.shape)\n",
    "    x = self.fc(x)\n",
    "    print(\"Tamaño salida fc (nro clases): \", x.shape)\n",
    "\n",
    "  def forward(self, x):\n",
    "    self.conv1_out = self.conv1(x)\n",
    "    self.conv2_out = self.conv2(self.conv1_out)\n",
    "    self.conv3_out = self.conv3(self.conv2_out)\n",
    "    self.conv4_out = self.conv4(self.conv3_out)\n",
    "    self.conv5_out = self.conv5(self.conv4_out)\n",
    "    self.conv6_out = self.conv6(self.conv5_out)\n",
    "    self.conv7_out = self.conv7(self.conv6_out)\n",
    "    self.conv8_out = self.conv8(self.conv7_out)\n",
    "    self.conv9_out = self.conv9(self.conv8_out)\n",
    "    self.conv10_out = self.conv10(self.conv9_out)\n",
    "    self.conv11_out = self.conv11(self.conv10_out)\n",
    "    y = self.conv11_out.view(self.conv11_out.shape[0], -1)\n",
    "    #y = self.conv6_out.view(self.conv6_out.shape[0], -1)\n",
    "    y = self.fc(y)\n",
    "    y = torch.nn.functional.softmax(y, dim=1)\n",
    "    # x = self.sm(x)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ILRsTXyWlu1K"
   },
   "source": [
    "### 4.4 Construyo mi CNN version 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "C04fBuSblu1Q"
   },
   "outputs": [],
   "source": [
    "def block(c_in, c_out, k=3, p=1, s=1, pk=3, ps=2, pp=1):\n",
    "    return torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(c_in, c_out, k, padding=p, stride=s), # conv\n",
    "        torch.nn.ReLU(),#Sigmoid(),#ReLU(),                                      # activation\n",
    "        torch.nn.MaxPool2d(pk, stride=ps, padding=pp)         # pooling\n",
    "    )\n",
    "\n",
    "class CNN6(torch.nn.Module):\n",
    "  def __init__(self, n_channels=1, n_outputs=10):\n",
    "    super().__init__()\n",
    "    self.conv1 = block(n_channels, 4,k=2,pk=3,ps=2)\n",
    "    self.conv1_out = None\n",
    "    self.conv2 = block(4, 8,k=3,pk=2,ps=2)\n",
    "    self.conv2_out = None\n",
    "    self.conv3 = block(8, 8,k=4,pk=2,ps=2)\n",
    "    self.conv3_out = None\n",
    "    self.conv4 = block(8, 8,k=3,pk=2,ps=2)\n",
    "    self.conv4_out = None\n",
    "    self.conv5 = block(8, 8,k=2,pk=2,ps=1)\n",
    "    self.conv5_out = None\n",
    "    self.conv6 = block(8, 8,k=2,pk=2,ps=1)\n",
    "    self.conv6_out = None\n",
    "    self.conv7 = block(8, 8,k=3,pk=2,ps=1)\n",
    "    self.conv7_out = None\n",
    "    self.conv8 = block(8, 8,k=2,pk=2,ps=2)\n",
    "    self.conv8_out = None\n",
    "    self.conv9 = block(8, 4,k=2,pk=2,ps=1)\n",
    "    self.conv9_out = None        \n",
    "    self.conv10 = block(4,4,k=3,pk=2,ps=2)\n",
    "    self.conv10_out = None\n",
    "    self.conv11 = block(4, 4,k=2,pk=2,ps=2)\n",
    "    self.conv11_out = None        \n",
    "    self.fc = torch.nn.Linear(4*3*3, n_outputs) # verificar la dim de la salida para calcular el tamaño de la fully conected!!\n",
    "    #self.sm = torch.nn.Softmax(dim=1)\n",
    "    print('Red creada')\n",
    "    print('arquitectura:')\n",
    "    print(self)\n",
    "    # Me fijo en el número de capas\n",
    "    i=0\n",
    "    for layer in self.children():\n",
    "        i=i+1\n",
    "    print('Número total de capas de CNN (conv+act+polling) + finales : ', i)\n",
    "    self.tot_capas=i\n",
    "    # Me fijo en el número de parámetros entrenables\n",
    "    pytorch_total_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "    print('Número total de parámetros a entrenar: ', pytorch_total_params)\n",
    "    self.tot_param=pytorch_total_params\n",
    "\n",
    "  def validar_dim(self,tam):\n",
    "    # es una funcion forward que imprime la dimension de cada paso\n",
    "    # la defino distinto de la forward standard para que cuando entrenemos\n",
    "    # no nos llene la pantalla de información inecesaria.\n",
    "\n",
    "    print(\"Validacion de dimensiones\")\n",
    "    #tam = input(\"Ingrese tamaño de entrada: \")\n",
    "    x = torch.randn(1, 1, int(tam), int(tam))\n",
    "    print(\"Tamaño entrada: \", x.shape)\n",
    "    x = self.conv1(x)\n",
    "    print(\"Tamaño salida conv1: \", x.shape)\n",
    "    x = self.conv2(x)\n",
    "    print(\"Tamaño salida conv2: \", x.shape)\n",
    "    x = self.conv3(x)\n",
    "    print(\"Tamaño salida conv3: \", x.shape)\n",
    "    x = self.conv4(x)\n",
    "    print(\"Tamaño salida conv4: \", x.shape)\n",
    "    x = self.conv5(x)\n",
    "    print(\"Tamaño salida conv5: \", x.shape)    \n",
    "    x = self.conv6(x)\n",
    "    print(\"Tamaño salida conv6: \", x.shape)\n",
    "    x = self.conv7(x)\n",
    "    print(\"Tamaño salida conv7: \", x.shape)\n",
    "    x = self.conv8(x)\n",
    "    print(\"Tamaño salida conv8: \", x.shape)\n",
    "    x = self.conv9(x)\n",
    "    print(\"Tamaño salida conv9: \", x.shape)\n",
    "    x = self.conv10(x)\n",
    "    print(\"Tamaño salida conv10: \", x.shape)\n",
    "    x = self.conv11(x)\n",
    "    print(\"Tamaño salida conv11: \", x.shape)                \n",
    "    x = x.view(x.shape[0], -1)\n",
    "    print(\"Tamaño imagen vectorizada: \", x.shape)\n",
    "    x = self.fc(x)\n",
    "    print(\"Tamaño salida fc (nro clases): \", x.shape)\n",
    "\n",
    "  def forward(self, x):\n",
    "    self.conv1_out = self.conv1(x)\n",
    "    self.conv2_out = self.conv2(self.conv1_out)\n",
    "    self.conv3_out = self.conv3(self.conv2_out)\n",
    "    self.conv4_out = self.conv4(self.conv3_out)\n",
    "    self.conv5_out = self.conv5(self.conv4_out)\n",
    "    self.conv6_out = self.conv6(self.conv5_out)\n",
    "    self.conv7_out = self.conv7(self.conv6_out)\n",
    "    self.conv8_out = self.conv8(self.conv7_out)\n",
    "    self.conv9_out = self.conv9(self.conv8_out)\n",
    "    self.conv10_out = self.conv10(self.conv9_out)\n",
    "    self.conv11_out = self.conv11(self.conv10_out)\n",
    "    y = self.conv11_out.view(self.conv11_out.shape[0], -1)\n",
    "    y = self.fc(y)\n",
    "    y = torch.nn.functional.softmax(y, dim=1)\n",
    "    # x = self.sm(x)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MdBnBqTdtezK"
   },
   "source": [
    "### 4.4 Construyo mi CNN version 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "qjmGml6stezQ"
   },
   "outputs": [],
   "source": [
    "def block(c_in, c_out, k=3, p=1, s=1, pk=3, ps=2, pp=1):\n",
    "    return torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(c_in, c_out, k, padding=p, stride=s), # conv\n",
    "        torch.nn.ReLU(),                                      # activation\n",
    "        torch.nn.MaxPool2d(pk, stride=ps, padding=pp)         # pooling\n",
    "    )\n",
    "\n",
    "class CNN7(torch.nn.Module):\n",
    "  def __init__(self, n_channels=1, n_outputs=10):\n",
    "    super().__init__()\n",
    "    self.conv1 = block(n_channels, 8,k=5,pk=2,ps=1)\n",
    "    self.conv1_out = None\n",
    "    self.conv2 = block(8, 8,k=3,pk=2,ps=1)\n",
    "    self.conv2_out = None\n",
    "    self.conv3 = block(8, 8,k=2,pk=2,ps=1)\n",
    "    self.conv3_out = None\n",
    "    self.conv4 = block(8, 8,k=3,pk=2,ps=1)\n",
    "    self.conv4_out = None\n",
    "    self.conv5 = block(8, 8,k=5,pk=2,ps=1)\n",
    "    self.conv5_out = None\n",
    "    self.conv6 = block(8, 8,k=2,pk=2,ps=2)\n",
    "    self.conv6_out = None\n",
    "    self.conv7 = block(8, 8,k=3,pk=2,ps=2)\n",
    "    self.conv7_out = None\n",
    "    self.conv8 = block(8, 8,k=2,pk=2,ps=2)\n",
    "    self.conv8_out = None\n",
    "    self.conv9 = block(8, 8,k=1,pk=2,ps=2)\n",
    "    self.conv9_out = None        \n",
    "    self.conv10 = block(8,8,k=1,pk=2,ps=1)\n",
    "    self.conv10_out = None\n",
    "    self.conv11 = block(8, 8,k=2,pk=2,ps=2)\n",
    "    self.conv11_out = None        \n",
    "    self.fc = torch.nn.Linear(200, n_outputs) # verificar la dim de la salida para calcular el tamaño de la fully conected!!\n",
    "    #self.sm = torch.nn.Softmax(dim=1)\n",
    "    print('Red creada')\n",
    "    print('arquitectura:')\n",
    "    print(self)\n",
    "    # Me fijo en el número de capas\n",
    "    i=0\n",
    "    for layer in self.children():\n",
    "        i=i+1\n",
    "    print('Número total de capas de CNN (conv+act+polling) + finales : ', i)\n",
    "    self.tot_capas=i\n",
    "    # Me fijo en el número de parámetros entrenables\n",
    "    pytorch_total_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "    print('Número total de parámetros a entrenar: ', pytorch_total_params)\n",
    "    self.tot_param=pytorch_total_params\n",
    "\n",
    "  def validar_dim(self,tam):\n",
    "    # es una funcion forward que imprime la dimension de cada paso\n",
    "    # la defino distinto de la forward standard para que cuando entrenemos\n",
    "    # no nos llene la pantalla de información inecesaria.\n",
    "\n",
    "    print(\"Validacion de dimensiones\")\n",
    "    #tam = input(\"Ingrese tamaño de entrada: \")\n",
    "    x = torch.randn(1, 1, int(tam), int(tam))\n",
    "    print(\"Tamaño entrada: \", x.shape)\n",
    "    x = self.conv1(x)\n",
    "    print(\"Tamaño salida conv1: \", x.shape)\n",
    "    x = self.conv2(x)\n",
    "    print(\"Tamaño salida conv2: \", x.shape)\n",
    "    x = self.conv3(x)\n",
    "    print(\"Tamaño salida conv3: \", x.shape)\n",
    "    x = self.conv4(x)\n",
    "    print(\"Tamaño salida conv4: \", x.shape)\n",
    "    x = self.conv5(x)\n",
    "    print(\"Tamaño salida conv5: \", x.shape)    \n",
    "    x = self.conv6(x)\n",
    "    print(\"Tamaño salida conv6: \", x.shape)\n",
    "    x = self.conv7(x)\n",
    "    print(\"Tamaño salida conv7: \", x.shape)\n",
    "    x = self.conv8(x)\n",
    "    print(\"Tamaño salida conv8: \", x.shape)\n",
    "    x = self.conv9(x)\n",
    "    print(\"Tamaño salida conv9: \", x.shape)\n",
    "    x = self.conv10(x)\n",
    "    print(\"Tamaño salida conv10: \", x.shape)\n",
    "    x = self.conv11(x)\n",
    "    print(\"Tamaño salida conv11: \", x.shape)                \n",
    "    x = x.view(x.shape[0], -1)\n",
    "    print(\"Tamaño imagen vectorizada: \", x.shape)\n",
    "    x = self.fc(x)\n",
    "    print(\"Tamaño salida fc (nro clases): \", x.shape)\n",
    "\n",
    "  def forward(self, x):\n",
    "    self.conv1_out = self.conv1(x)\n",
    "    self.conv2_out = self.conv2(self.conv1_out)\n",
    "    self.conv3_out = self.conv3(self.conv2_out)\n",
    "    self.conv4_out = self.conv4(self.conv3_out)\n",
    "    self.conv5_out = self.conv5(self.conv4_out)\n",
    "    self.conv6_out = self.conv6(self.conv5_out)\n",
    "    self.conv7_out = self.conv7(self.conv6_out)\n",
    "    self.conv8_out = self.conv8(self.conv7_out)\n",
    "    self.conv9_out = self.conv9(self.conv8_out)\n",
    "    self.conv10_out = self.conv10(self.conv9_out)\n",
    "    self.conv11_out = self.conv11(self.conv10_out)\n",
    "    y = self.conv11_out.view(self.conv11_out.shape[0], -1)\n",
    "    #y = self.conv6_out.view(self.conv6_out.shape[0], -1)\n",
    "    y = self.fc(y)\n",
    "    y = torch.nn.functional.softmax(y, dim=1)\n",
    "    # x = self.sm(x)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qeCxbd3uQbyx"
   },
   "source": [
    "### Armo mi funcion de fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "wIY3x62QQbXI"
   },
   "outputs": [],
   "source": [
    "def fit(model, dataloader, epochs=5):\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        train_loss, train_acc = [], []\n",
    "        bar = tqdm(dataloader['train'])\n",
    "        for batch in bar:\n",
    "            X, y = batch\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = model(X)\n",
    "            loss = criterion(y_hat, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss.append(loss.item())\n",
    "            ####\n",
    "            acc = (y == torch.argmax(y_hat, axis=1)).sum().item() / len(y)\n",
    "            train_acc.append(acc)\n",
    "            bar.set_description(f\"loss {np.mean(train_loss):.5f} acc {np.mean(train_acc):.5f}\")\n",
    "        bar = tqdm(dataloader['validation'])\n",
    "        val_loss, val_acc = [], []\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in bar:\n",
    "                X, y = batch\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                y_hat = model(X)\n",
    "                loss = criterion(y_hat, y)\n",
    "                val_loss.append(loss.item())\n",
    "                acc = (y == torch.argmax(y_hat, axis=1)).sum().item() / len(y)\n",
    "                val_acc.append(acc)\n",
    "                bar.set_description(f\"val_loss {np.mean(val_loss):.5f} val_acc {np.mean(val_acc):.5f}\")\n",
    "        print(f\"\\nEpoch {epoch}/{epochs} loss {np.mean(train_loss):.5f} val_loss {np.mean(val_loss):.5f} acc {np.mean(train_acc):.5f} val_acc {np.mean(val_acc):.5f}\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VZAfOG3dsYal"
   },
   "source": [
    "### Creo el modelo y valido dimensiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KO3LTlNn_WWL",
    "outputId": "d3354c01-edb7-4580-db22-ae52b6091984"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Red creada\n",
      "arquitectura:\n",
      "CNN7(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv2d(8, 8, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv4): Sequential(\n",
      "    (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv5): Sequential(\n",
      "    (0): Conv2d(8, 8, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv6): Sequential(\n",
      "    (0): Conv2d(8, 8, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv7): Sequential(\n",
      "    (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv8): Sequential(\n",
      "    (0): Conv2d(8, 8, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv9): Sequential(\n",
      "    (0): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv10): Sequential(\n",
      "    (0): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv11): Sequential(\n",
      "    (0): Conv2d(8, 8, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Linear(in_features=200, out_features=10, bias=True)\n",
      ")\n",
      "Número total de capas de CNN (conv+act+polling) + finales :  12\n",
      "Número total de parámetros a entrenar:  6778\n",
      "Validacion de dimensiones\n",
      "Tamaño entrada:  torch.Size([1, 1, 28, 28])\n",
      "Tamaño salida conv1:  torch.Size([1, 8, 27, 27])\n",
      "Tamaño salida conv2:  torch.Size([1, 8, 28, 28])\n",
      "Tamaño salida conv3:  torch.Size([1, 8, 30, 30])\n",
      "Tamaño salida conv4:  torch.Size([1, 8, 31, 31])\n",
      "Tamaño salida conv5:  torch.Size([1, 8, 30, 30])\n",
      "Tamaño salida conv6:  torch.Size([1, 8, 16, 16])\n",
      "Tamaño salida conv7:  torch.Size([1, 8, 9, 9])\n",
      "Tamaño salida conv8:  torch.Size([1, 8, 6, 6])\n",
      "Tamaño salida conv9:  torch.Size([1, 8, 5, 5])\n",
      "Tamaño salida conv10:  torch.Size([1, 8, 8, 8])\n",
      "Tamaño salida conv11:  torch.Size([1, 8, 5, 5])\n",
      "Tamaño imagen vectorizada:  torch.Size([1, 200])\n",
      "Tamaño salida fc (nro clases):  torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "#model = CNN()\n",
    "model = CNN7()\n",
    "model.validar_dim(28)\n",
    "n_parameter= model.tot_param\n",
    "n_layers= model.tot_capas\n",
    "n_epochs = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6wYSjT9cT6hV"
   },
   "source": [
    "### Hago el entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yZw6adJ_QjuF",
    "outputId": "5184b10b-e492-42aa-885d-381ebb141cc3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 2.26418 acc 0.15329: 100%|██████████| 875/875 [00:10<00:00, 82.20it/s]\n",
      "val_loss 2.03283 val_acc 0.42543: 100%|██████████| 110/110 [00:00<00:00, 149.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/1 loss 2.26418 val_loss 2.03283 acc 0.15329 val_acc 0.42543\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fit(model, dataloader,epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VBwBJDqDT4ig"
   },
   "source": [
    "### Calculo el score en test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6L4k9OjMRGsS",
    "outputId": "f756764b-a292-4f10-f174-f8618d9334dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4297348484848485"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "val_acc = []\n",
    "for x,y in dataloader['test']:\n",
    "  longitud = len(y)\n",
    "  y_hat = model(x.to(device))  \n",
    "  acc = (y.to(device) == torch.argmax(y_hat, dim=1)).sum().item() / longitud\n",
    "  val_acc.append(acc)\n",
    "\n",
    "test_acc = np.mean(val_acc)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1aQ5n86Kwk7B"
   },
   "source": [
    "### score final obtenido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Cbwau-5BZVt",
    "outputId": "e7391ce4-54bd-45c3-ba4d-efd22410e9f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score final:  13.46040582583556 con n_parameter=  6778 ,  12  layers, 1  epochs (acc= 0.4297348484848485 )\n"
     ]
    }
   ],
   "source": [
    "score=(1/np.log10(n_parameter))*(10/n_epochs)*test_acc*n_layers\n",
    "print(\"Score final: \",score, \"con n_parameter= \",n_parameter,\", \",n_layers,\" layers,\",n_epochs,\" epochs (acc=\",test_acc,\")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A7QjOBdfmtbr"
   },
   "source": [
    "### Resumen de resultados con los modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cDia_YSMF_aX"
   },
   "source": [
    "#### Para modelo base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sYS_1IRlQhuj"
   },
   "source": [
    "* Score final:  0.7644789759231583 con n_parameter= 137226, 2 layers, 5 epochs (acc = 0.9812973484848484)\n",
    "* Score final 3.403603291320133 con n_parameter= 137226, 2 layers, 1 epochs (acc = 0.8742897727272727)\n",
    "* Score final: 1.886313256524483 con n_parameter= 137226, 2 layers, 2 epochs (acc = 0.9690814393939393)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zXVu8EH3GBoL"
   },
   "source": [
    "#### Para modelo 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HZfFPWHYlD7k"
   },
   "source": [
    "* Score final:  3.7760370099968528 con n_parameter=  3262 ,  12  layers, 1  epochs (acc= 0.11055871212121213 )\n",
    "* Score final:  5.461103632873392 con n_parameter=  3262 ,  12  layers, 3  epochs (acc= 0.4796875 )\n",
    "* Score final:  5.274808359403741 con n_parameter=  3262 ,  12  layers, 5  epochs (acc= 0.7722064393939394 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s32WGnfRYudw"
   },
   "source": [
    "#### Para modelo 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qHdYuROhYwF-"
   },
   "source": [
    "* Score final 4.15379885045299 con n_parameter= 1098, 8 layers, 3 epochs (acc = 0.47362689393939394)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tAAZhMj8hOKh"
   },
   "source": [
    "#### Para modelo 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TWe6pHlBhTIZ"
   },
   "source": [
    "* Score final:  3.9518237990429035 con n_parameter=  1070 ,  12  layers, 1  epochs (acc= 0.09976325757575757 )\n",
    "* Score final:  1.4598178406526152 con n_parameter=  1070 ,  12  layers, 3  epochs (acc= 0.11055871212121213 )\n",
    "* Score final:  0.8758907043915691 con n_parameter=  1070 ,  12  layers, 5  epochs (acc= 0.11055871212121213 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oJQB5yGMlG5H"
   },
   "source": [
    "#### Para modelo 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QWkgkv1RGvq0"
   },
   "source": [
    "* Score final:  7.211131309779322 con n_parameter=  5754 ,  12  layers, 1  epochs (acc= 0.2259469696969697 )\n",
    "* Score final:  7.82389613503404 con n_parameter=  5754 ,  12  layers, 2  epochs (acc= 0.4902935606060606 )\n",
    "* Score final:  5.936237949549406 con n_parameter=  5754 ,  12  layers, 3  epochs (acc= 0.5580018939393939 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BjLfW8cpmQxG"
   },
   "source": [
    "#### Para modelo 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nd9VvsKqmSEs"
   },
   "source": [
    "* Score final:  3.680307910618348 con n_parameter=  4026 ,  12  layers, 1  epochs (acc= 0.11055871212121213 )\n",
    "* Score final:  6.072902089769805 con n_parameter=  4026 ,  12  layers, 2  epochs (acc= 0.36486742424242424 )\n",
    "* Score final:  6.311425971485827 con n_parameter=  4026 ,  12  layers, 3  epochs (acc= 0.5687973484848485 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bF2TzPAzu1Wo"
   },
   "source": [
    "#### Para modelo 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "npbANKOmu3EA"
   },
   "source": [
    "* Score final:  13.46040582583556 con n_parameter=  6778 ,  12  layers, 1  epochs (acc= 0.4297348484848485 )\n",
    "* Score final:  7.660092121026957 con n_parameter=  6778 ,  12  layers, 2  epochs (acc= 0.4891098484848485 )\n",
    "* Score final:  6.358444973259033 con n_parameter=  6778 ,  12  layers, 3  epochs (acc= 0.6089962121212121 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mejor resultado\n",
    "\n",
    "El mejor score obtenido fue: 13.46040582583556\n",
    "Con modelo 7\n",
    "n_parameter: 677812\n",
    "layers: 12\n",
    "epochs: 1\n",
    "acc: 0.4297348484848485 "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CNN_TP.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
